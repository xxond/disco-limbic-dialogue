{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.display.max_rows = 250\n",
    "pd.options.display.max_colwidth = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = pd.read_csv('table/actor.csv', index_col=0)\n",
    "convs = pd.read_csv('table/convs.csv', index_col=[0, 1])\n",
    "convs.drop(['isGroup', 'canvasRect_width', 'canvasRect_height'], axis=1, inplace=True)\n",
    "convs['Actor'] = convs['Actor'].fillna(-1.0)\n",
    "convs.outgoingLinks = convs.outgoingLinks.apply(lambda x: [tuple(i) for i in json.loads(x.replace('(', '[').replace(')', ']'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('actors.txt', 'r') as f:\n",
    "    act_list = ['You'] + [i.replace('\\n', '') for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_idx = list(act[act['Name'].apply(lambda x: x == 'You')].index)[0]\n",
    "act_list_idx = list(act[act['Name'].apply(lambda x: x in act_list)].index)\n",
    "act_list_idx.append(0)\n",
    "act_list_idx.append(-1)\n",
    "conv_idx_act = list(set(convs[convs.apply(lambda x: x.Actor in act_list_idx, axis=1)].index.get_level_values(level=0)))\n",
    "cut_convs = convs.loc[conv_idx_act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = convs.loc[convs['Actor'].apply(lambda x: x in act_list_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clear outgoing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_removed = 0\n",
    "rem_links = 0\n",
    "\n",
    "index = convs.index\n",
    "for idx, row in convs.iterrows():\n",
    "    links = row['outgoingLinks']\n",
    "    cut_links = []\n",
    "    if links:\n",
    "        for i in links:\n",
    "            if i in index:\n",
    "                cut_links.append(i)\n",
    "            else:\n",
    "                link_removed += 1\n",
    "                #print(f'removing link {i}')\n",
    "                #a = 1/0\n",
    "    rem_links += len(cut_links)\n",
    "    convs.at[idx, 'outgoingLinks'] = cut_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add incoming links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs['ingoingLinks'] = [[]]*len(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_from, row in convs.iterrows():\n",
    "    links = row['outgoingLinks']\n",
    "    cut_links = []\n",
    "    for idx_to in links:\n",
    "        ing_links = set(convs.loc[idx_to, 'ingoingLinks'])\n",
    "        ing_links.add(idx_from)\n",
    "        convs.at[idx_to, 'ingoingLinks'] = list(ing_links)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clear solo lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = convs[convs.apply(lambda x: len(x['outgoingLinks'])!=0 or len(x['ingoingLinks'])!=0, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove tmp actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fixing links before removing this actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_act_idx = list(convs[convs['Actor'].apply(lambda x: x in (0.0, -1.0))].index)\n",
    "for idx in tmp_act_idx:\n",
    "    outg, ing = convs.loc[idx, ['outgoingLinks', 'ingoingLinks']]\n",
    "    for i in ing:\n",
    "        init = set(convs.loc[i, 'outgoingLinks'])\n",
    "        init.remove(idx)\n",
    "        convs.at[i, 'outgoingLinks'] = list(init.union(set(outg)))\n",
    "\n",
    "    for i in outg:\n",
    "        init = set(convs.loc[i, 'ingoingLinks'])\n",
    "        init.remove(idx)\n",
    "        convs.at[i, 'ingoingLinks'] = list(init.union(set(ing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = convs[convs['Actor'].apply(lambda x: x not in (0.0, -1.0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking if any links going outside of current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = convs.index\n",
    "for idx, row in convs.iterrows():\n",
    "    for i in row['outgoingLinks']:\n",
    "        if i not in index:\n",
    "            print('error', idx)\n",
    "\n",
    "    for i in row['ingoingLinks']:\n",
    "        if i not in index:\n",
    "            print('error', idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove sololines once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = convs[convs.apply(lambda x: len(x['outgoingLinks'])!=0 or len(x['ingoingLinks'])!=0, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing NaN text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_text_idx = convs[convs['Dialogue Text'].isna()].index\n",
    "for idx in nan_text_idx:\n",
    "    outg, ing = convs.loc[idx, ['outgoingLinks', 'ingoingLinks']]\n",
    "    for i in ing:\n",
    "        init = set(convs.loc[i, 'outgoingLinks'])\n",
    "        init.remove(idx)\n",
    "        convs.at[i, 'outgoingLinks'] = list(init.union(set(outg)))\n",
    "    \n",
    "    for i in outg:\n",
    "        init = set(convs.loc[i, 'ingoingLinks'])\n",
    "        init.remove(idx)\n",
    "        convs.at[i, 'ingoingLinks'] = list(init.union(set(ing)))\n",
    "convs = convs[~convs['Dialogue Text'].isna()]\n",
    "convs = convs[convs.apply(lambda x: len(x['outgoingLinks'])!=0 or len(x['ingoingLinks'])!=0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = convs.index\n",
    "for idx, row in convs.iterrows():\n",
    "    for i in row['outgoingLinks']:\n",
    "        if i not in index:\n",
    "            print('error', idx)\n",
    "\n",
    "    for i in row['ingoingLinks']:\n",
    "        if i not in index:\n",
    "            print('error', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs['ActorName'] = convs['Actor'].map(act['Name'])\n",
    "convs['ActorName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_dict = convs['outgoingLinks'].to_dict()\n",
    "def recursive_count(node, prev_nodes):\n",
    "    if len(prev_nodes) > 5:\n",
    "        return 1\n",
    "    links = convs_dict[node]\n",
    "    if len(links) == 0:\n",
    "        return 1\n",
    "    \n",
    "    sum_ = 0\n",
    "    for link in links:\n",
    "        if link not in prev_nodes:\n",
    "            sum_ += recursive_count(link, prev_nodes+[node])\n",
    "    return sum_\n",
    "\n",
    "\n",
    "def recursive_path(node, prev_nodes, max_len=7, min_len=3):\n",
    "    if len(prev_nodes) >= max_len:\n",
    "        return [prev_nodes]\n",
    "    links = convs_dict[node]\n",
    "    if len(links) == 0:\n",
    "        if len(prev_nodes) > min_len - 1:\n",
    "            return [prev_nodes+[node]]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    sum_ = []\n",
    "    for link in links:\n",
    "        if link not in prev_nodes:\n",
    "            sum_ += recursive_path(link, prev_nodes+[node])\n",
    "    return sum_\n",
    "\n",
    "def filter_paths(paths):\n",
    "    ret_path = []\n",
    "    for path in paths:\n",
    "        # You not only on last position\n",
    "        for node in path[:-1]:\n",
    "            if convs.loc[node]['ActorName'] == 'You':\n",
    "                ret_path.append(path)\n",
    "                break\n",
    "    return ret_path\n",
    "\n",
    "\n",
    "def populate_dial(path):\n",
    "    ret_path = []\n",
    "    cur = []\n",
    "    for node in path:\n",
    "        if convs.loc[node]['ActorName'] == 'You' and cur:\n",
    "            ret_path.append(cur[:])\n",
    "        cur.append(node)\n",
    "    if convs.loc[path[-1]]['ActorName'] != 'You':\n",
    "        ret_path.append(cur[:])\n",
    "    return ret_path\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_example(path):\n",
    "    lines = []\n",
    "    buffer = []\n",
    "    for node in path:\n",
    "        text, actor = convs.loc[node][['Dialogue Text', 'ActorName']]\n",
    "        if actor == 'You':\n",
    "            if buffer:\n",
    "                lines.append('\\n'.join(buffer))\n",
    "            lines.append(text)\n",
    "            buffer = []\n",
    "        else:\n",
    "            buffer.append(f'[{actor}]: {text}')\n",
    "    if buffer:\n",
    "        lines.append('\\n'.join(buffer))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starts = list(convs[convs['ingoingLinks'].apply(len) == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, test_start = train_test_split(all_starts, test_size=0.025, random_state=42)\n",
    "len(train_start), len(test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = []\n",
    "for i in train_start:\n",
    "    # filter\n",
    "    paths = filter_paths(recursive_path(i, []))\n",
    "    # if there is too much from one conv, so sample dialogues from here\n",
    "    if len(paths) > 10:\n",
    "        paths = random.sample(paths, 10)\n",
    "    # populate dialogues by cutting them\n",
    "    new_paths = []\n",
    "    for p in paths:\n",
    "        new_paths.extend(populate_dial(p))\n",
    "    paths = new_paths\n",
    "    if paths:\n",
    "        samples_train.append((i, paths))\n",
    "\n",
    "\n",
    "samples_test = []\n",
    "for i in test_start:\n",
    "    # filter\n",
    "    paths = filter_paths(recursive_path(i, []))\n",
    "    # if there is too much from one conv, so sample dialogues from here\n",
    "    if len(paths) > 10:\n",
    "        paths = random.sample(paths, 10)\n",
    "    # populate dialogues by cutting them\n",
    "    new_paths = []\n",
    "    for p in paths:\n",
    "        new_paths.extend(populate_dial(p))\n",
    "    paths = new_paths\n",
    "    if paths:\n",
    "        samples_test.append((i, paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = []\n",
    "for sample in samples_train:\n",
    "    paths = sample[1]\n",
    "    for i in paths:\n",
    "        dataset_train.append(path_to_example(i))\n",
    "\n",
    "dataset_test = []\n",
    "for sample in samples_test:\n",
    "    paths = sample[1]\n",
    "    for i in paths:\n",
    "        dataset_test.append(path_to_example(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [len(i[1]) for i in samples_train]\n",
    "print(sum(x), sum(x)/len(x))\n",
    "fig = px.histogram(x=x,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = list(set([tuple(i) for i in dataset_train]))\n",
    "dataset_test = list(set([tuple(i) for i in dataset_test]))\n",
    "len(dataset_train), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/v1/train.json', 'w') as f:\n",
    "    json.dump(dataset_train, f, indent=4)\n",
    "\n",
    "with open('dataset/v1/test.json', 'w') as f:\n",
    "    json.dump(dataset_test, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "for sample in dataset_train:\n",
    "    for line in sample:\n",
    "        if line == '':\n",
    "            print(sample)\n",
    "        freq_dict[line] = freq_dict.get(line, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in freq_dict.items():\n",
    "    if v > 100:\n",
    "        print(f'{k}', v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
